{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb25a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Base Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from docx import Document\n",
    "\n",
    "\n",
    "knowledge_base_path = 'knowledge_base.txt'\n",
    "\n",
    "with open(knowledge_base_path, 'r', encoding='utf-8') as file:\n",
    "    knowledge_base = file.read()\n",
    "\n",
    "print(\"Knowledge Base Loaded Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4321d4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b6693f98fb42ffb62f10f2a8d39c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated successfully! Embeddings shape: torch.Size([52, 384])\n",
      "Embeddings saved successfully to knowledge_base_embeddings.pt\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "corpus = knowledge_base.split(\"\\n\")\n",
    "\n",
    "embeddings = model.encode(corpus, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "print(f\"Embeddings generated successfully! Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "embedding_file_path = \"knowledge_base_embeddings.pt\"  \n",
    "torch.save(embeddings, embedding_file_path)\n",
    "\n",
    "print(f\"Embeddings saved successfully to {embedding_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2302dd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings shape: torch.Size([52, 384])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embeddings = torch.load('knowledge_base_embeddings.pt')\n",
    "print(f\"Loaded embeddings shape: {embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a43a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "embeddings = torch.load(\"knowledge_base_embeddings.pt\")\n",
    "\n",
    "with open(\"knowledge_base.txt\", \"r\") as file:\n",
    "    corpus = file.readlines()\n",
    "\n",
    "embeddings_np = embeddings.cpu().numpy()\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings_np.shape[1]) \n",
    "index.add(embeddings_np)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b6dfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6653407804b4eb6b06e6961db5ffa59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf22b7c972f4edf808a6012a8917614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc982de794249b2afe782914349d9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1e808325de4ee69948924b505b2018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c674b633ba10419487a8a58fc432a2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc9a0c91d994f319ca1e907a21811dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def get_relevant_documents(query, top_k=5):\n",
    "\n",
    "    query_embedding = sentence_model.encode([query], convert_to_tensor=True)\n",
    "\n",
    "    query_embedding_np = query_embedding.cpu().numpy()  \n",
    "    D, I = index.search(query_embedding_np, top_k)  \n",
    "    relevant_documents = [corpus[i] for i in I[0]]\n",
    "    return relevant_documents\n",
    "\n",
    "def generate_answer(query, relevant_docs):\n",
    "    input_text = \" \".join(relevant_docs) + \" \" + query\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"longest\")\n",
    "\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, min_length=50, max_length=500)\n",
    "    answer = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1631ea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a legal question: what is right to information act\n",
      "Answer: The Right to Information Act, 2005 was enacted by Parliament in the Fifty-sixth Year of the Republic of India as follows. The Act provides for setting out the practical regime of right to information for citizens to secure access to information under the control of public authorities. It is intended to promote transparency and accountability.\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Ask a legal question: \") \n",
    "\n",
    "if query:\n",
    "    relevant_documents = get_relevant_documents(query, top_k=5)\n",
    "    answer = generate_answer(query, relevant_documents)\n",
    "\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1ed91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
